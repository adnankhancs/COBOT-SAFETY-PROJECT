{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "734dc2f4-a190-4603-a41b-29bd18951444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "print(torch.cuda.is_available())  # Should return True if GPU is available\n",
    "\n",
    "# Get the name of the GPU\n",
    "print(torch.cuda.get_device_name(0))  # Should return the name of your GPU (e.g., \"NVIDIA GeForce RTX 3060\")\n",
    "\n",
    "# Check CUDA version\n",
    "print(torch.version.cuda)  # Should match your installed CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08160598-caf5-4b21-a200-e889d3aa7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c415df60-13ca-4e61-9037-600c45229d47",
   "metadata": {},
   "source": [
    "Model_1 training yolo11 only simulation image data set augmented fromm 44 to 106 images as test valid and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33926d9a-c354-49c6-9690-36cc7254fc26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.94 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.91 ðŸš€ Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11l.pt, data=/mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/data.yaml, epochs=100, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=model_3.23, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/model_3.23\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1412566  ultralytics.nn.modules.head.Detect           [2, [256, 512, 512]]          \n",
      "YOLO11l summary: 357 layers, 25,312,022 parameters, 25,312,006 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/train/labels.cache... 192 images, 0 back\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/valid/labels.cache... 17 images, 0 backgro\u001b[0m\n",
      "/home/adnan/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/adnan/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/adnan/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/adnan/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/model_3.23/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/model_3.23\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      5.26G      1.531      2.627      1.754         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [02:03<00:00,  5.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35     0.0874       0.65      0.141     0.0505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      5.45G      1.798       2.42      1.974         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:52<00:00,  4.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35     0.0082       0.85    0.00911    0.00391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      5.45G      1.905      2.486      2.066         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:40<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35    0.00362       0.55    0.00631    0.00163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      5.46G      2.132      2.551      2.266         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:42<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35    0.00277      0.258    0.00227   0.000527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      5.46G      2.092      2.437      2.243         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:48<00:00,  4.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35   0.000922     0.0917   0.000542   0.000322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      5.47G      2.033      2.327      2.197         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:45<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35    0.00584      0.717    0.00588    0.00208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      5.45G      1.952      2.259       2.13         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:53<00:00,  4.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35   0.000386       0.05   0.000253   2.53e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      5.46G      1.847      2.088      2.078         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:41<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35     0.0111     0.0333     0.0024    0.00028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      5.45G      1.916      2.072      2.068         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:47<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35    0.00659      0.767    0.00732    0.00251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      5.45G      1.779      1.994      1.997         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:38<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35     0.0315      0.683     0.0378      0.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      5.45G      1.831      1.932      1.967         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:39<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35    0.00364      0.075    0.00213   0.000638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      5.45G      1.794      1.928       1.96         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:41<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35     0.0445      0.275     0.0225    0.00512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      5.46G      1.766       1.92      1.964         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:38<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.928      0.394      0.506      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      5.45G      1.736      1.945      1.952         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:37<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.915      0.267       0.42      0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      5.45G      1.682      1.894       1.93         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:36<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.847        0.5      0.659      0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      5.45G      1.711       1.85      1.909         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:37<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.292      0.667      0.385      0.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      5.45G      1.728      1.874      1.955         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.372        0.5      0.426      0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      5.45G      1.698      1.851       1.92         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:41<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.451      0.325      0.225      0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      5.47G      1.635      1.814      1.873         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:41<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.358      0.408      0.372      0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      5.47G      1.594       1.73      1.818         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:50<00:00,  4.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.676      0.475      0.549      0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      5.45G      1.609      1.764      1.842         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:52<00:00,  4.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.606       0.65      0.507      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      5.46G      1.557      1.681      1.819         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:46<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35     0.0234      0.317     0.0257    0.00733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      5.45G      1.559      1.683      1.828         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:37<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.563      0.476      0.508      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      5.45G      1.533      1.623      1.816         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:44<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.882      0.508      0.711      0.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      5.46G      1.517      1.541      1.753         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:44<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.844      0.556      0.638      0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      5.45G      1.527      1.579      1.762         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:40<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.707      0.606      0.718       0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      5.46G      1.478      1.516      1.667         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:40<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.786      0.725      0.792      0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      5.45G      1.483       1.58      1.756         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:48<00:00,  4.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.585       0.85      0.745      0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      5.45G      1.401      1.502      1.696         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:43<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.869        0.8      0.836      0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      5.47G      1.467      1.478      1.698         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:48<00:00,  4.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.791      0.775      0.836      0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      5.45G      1.435      1.515      1.746         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:46<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.723        0.8      0.788      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      5.45G      1.447      1.484      1.694         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:46<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.812      0.825      0.833      0.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      5.45G      1.392      1.473      1.689         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:49<00:00,  4.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.78      0.667       0.72      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      5.44G      1.335      1.372      1.619         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:45<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.808      0.807      0.815      0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      5.45G      1.408      1.385      1.723         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:41<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.837      0.726      0.785      0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      5.46G      1.402      1.342       1.65         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:40<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.639      0.742      0.761       0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      5.45G      1.357      1.384      1.624         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:39<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.823       0.63      0.702      0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      5.46G      1.307      1.344      1.614         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:39<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.737       0.65      0.766      0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      5.45G      1.337      1.354      1.668         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:43<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.832      0.655      0.746      0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      5.45G      1.364      1.369       1.63         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:43<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.783      0.656      0.772      0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      5.45G      1.395      1.315      1.644         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:38<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.832       0.83      0.874      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      5.46G       1.34      1.345      1.627         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:49<00:00,  4.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.968      0.725      0.887      0.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      5.45G      1.285      1.272       1.54         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:57<00:00,  4.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.818      0.846      0.857      0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      5.46G      1.332      1.345       1.62         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:43<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.841      0.768      0.809      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      5.46G      1.329      1.338       1.63         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:32<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.826       0.65      0.819      0.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      5.45G      1.245      1.306      1.571         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:31<00:00,  3.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.833      0.676      0.822       0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      5.46G      1.256      1.273      1.531         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:41<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.775      0.683      0.765      0.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      5.45G      1.254      1.189      1.569         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:36<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.909      0.706      0.837      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      5.45G      1.295      1.249      1.596         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.887      0.742      0.801      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      5.45G      1.227      1.233      1.532         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.847       0.75      0.866      0.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      5.45G      1.182      1.183      1.538         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:37<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.817      0.811      0.861      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      5.46G      1.244       1.24      1.558         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:35<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.795      0.842      0.878      0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      5.45G      1.213      1.128      1.546         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:28<00:00,  3.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.662      0.865       0.81      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      5.45G      1.242      1.206      1.566         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:36<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.751      0.842      0.877      0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      5.45G      1.146      1.108      1.515         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:32<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.674      0.892      0.888      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      5.46G      1.158      1.112      1.522         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:30<00:00,  3.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.829      0.875      0.903      0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      5.46G      1.205      1.105      1.489         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:32<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.822      0.843      0.881      0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      5.45G      1.142      1.076      1.475         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:29<00:00,  3.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.929        0.8      0.889      0.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      5.45G      1.179       1.11      1.477         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:29<00:00,  3.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.841      0.843       0.88      0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      5.46G      1.174      1.123      1.498         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [43:50<00:00, 109.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.924      0.825      0.879      0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      5.45G      1.116      1.089      1.488         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.87      0.818      0.856      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      5.45G      1.121      1.091      1.496         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:24<00:00,  3.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.924      0.775       0.86      0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      5.47G      1.159      1.068      1.511         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:30<00:00,  3.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.803      0.781      0.845      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      5.44G      1.095      1.044      1.452         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:40<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.879      0.825      0.877      0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      5.47G      1.076      1.031      1.453         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:37<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.827      0.742      0.856      0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      5.46G       1.12      1.065      1.442         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:25<00:00,  3.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.76      0.875      0.837      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      5.46G      1.059      1.021      1.424         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:32<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.817      0.842      0.897      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      5.46G      1.104      1.049      1.451         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:32<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.855      0.772       0.88      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      5.46G      1.073      1.003      1.439         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:33<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.901      0.802      0.927      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      5.45G      1.056     0.9639      1.396         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:42<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.75      0.875      0.925      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      5.45G      1.124      1.041      1.481         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:45<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.918      0.775      0.906      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      5.45G      1.087      1.005      1.443         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:45<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.912      0.791      0.889      0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      5.46G       1.06     0.9889      1.411         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:42<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.791       0.85      0.888      0.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      5.45G       1.06     0.9751      1.417         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:35<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.898      0.825      0.903      0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      5.44G      0.981     0.9642      1.407         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:37<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.847      0.866      0.871      0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      5.46G      1.016     0.9559      1.429         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:36<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.77      0.875      0.833      0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      5.47G      1.031     0.9442      1.404         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:28<00:00,  3.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.763      0.925      0.891      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      5.45G     0.9864     0.8755      1.376         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:29<00:00,  3.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.795      0.861      0.897      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      5.46G      1.027     0.9553      1.425         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.818      0.875      0.893      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      5.45G       1.01     0.9259       1.39         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:31<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.848      0.799      0.903      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      5.45G     0.9364     0.9097      1.363         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:35<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.805      0.816      0.879       0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      5.45G     0.9592     0.8829       1.35         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.867      0.825      0.914      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      5.44G     0.9274     0.8411      1.343         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:28<00:00,  3.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.947       0.85       0.94      0.637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      5.47G     0.9371     0.8661       1.36         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.946      0.875      0.941      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      5.45G     0.9652     0.9023      1.352         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:38<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35        0.9      0.875        0.9      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      5.46G     0.9567     0.8837      1.386         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:38<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.85        0.9      0.903      0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      5.47G     0.9544     0.8734      1.392         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:40<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.917      0.925      0.941       0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      5.45G     0.9298     0.8547      1.327         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:42<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.939      0.832      0.931      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      5.46G     0.9198     0.8651      1.343         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:41<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.857      0.875      0.928      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      5.45G     0.9066     0.7958      1.295         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:33<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.848      0.872      0.911      0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      5.45G      0.803     0.7163      1.276         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:37<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.914        0.8      0.917       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      5.47G     0.7915     0.7067      1.272         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:37<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.925       0.85      0.931      0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      5.46G     0.7903     0.6618      1.276         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:29<00:00,  3.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.831      0.875      0.934      0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      5.46G     0.7242      0.648      1.181         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:55<00:00,  4.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.874      0.875      0.942       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      5.47G      0.724     0.6327      1.204         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.795      0.898       0.93      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      5.46G     0.7096     0.6116      1.214         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:43<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.816       0.85      0.919      0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      5.46G     0.6781     0.5776      1.177         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:42<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.852      0.842      0.921       0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      5.45G     0.7142     0.5972      1.219         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:48<00:00,  4.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.896      0.875      0.928      0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      5.47G     0.6899     0.5806      1.202         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:41<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.88      0.875      0.927       0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      5.45G     0.6825     0.5648      1.188         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:39<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.886      0.879      0.928       0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 3.632 hours.\n",
      "Optimizer stripped from runs/detect/model_3.23/weights/last.pt, 51.2MB\n",
      "Optimizer stripped from runs/detect/model_3.23/weights/best.pt, 51.2MB\n",
      "\n",
      "Validating runs/detect/model_3.23/weights/best.pt...\n",
      "Ultralytics 8.3.91 ðŸš€ Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "YOLO11l summary (fused): 190 layers, 25,280,854 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.808      0.904      0.911      0.637\n",
      "                 human         15         15      0.886          1      0.995      0.802\n",
      "                 robot         17         20      0.729      0.809      0.828      0.473\n",
      "Speed: 0.4ms preprocess, 171.6ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/model_3.23\u001b[0m\n",
      "Ultralytics 8.3.91 ðŸš€ Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "YOLO11l summary (fused): 190 layers, 25,280,854 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/valid/labels.cache... 17 images, 0 backgro\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.808      0.907      0.911       0.64\n",
      "                 human         15         15      0.886          1      0.995      0.802\n",
      "                 robot         17         20      0.731      0.814      0.828      0.478\n",
      "Speed: 8.5ms preprocess, 242.2ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/model_3.232\u001b[0m\n",
      "mAP50-95: 0.6399597204992509\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: Load a pretrained model\n",
    "# Choose from: yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt\n",
    "model = YOLO(\"yolo11l.pt\")  # Load YOLOv8n (smallest model)\n",
    "\n",
    "# Step 2: Train the model\n",
    "#\"C:\\Users\\adnan\\Desktop\\urfikhan\\Final_anotated_data\\Model_1\\data.yaml\"\n",
    "results = model.train(\n",
    "    data= \"/mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/data.yaml\",  # Path to your data.yaml file\n",
    "    epochs=100,                # Number of training epochs\n",
    "    imgsz=640,                # Image size (640x640)\n",
    "    batch=8, # Batch size (adjust based on GPU memory)\n",
    "    device=0,\n",
    "    iou=0.5-0.75\n",
    "    augment=True,# Use GPU (0) or CPU (-1)\n",
    "    name=\"model_3.2\"     # Name of the training run (optional)\n",
    ")\n",
    "\n",
    "# Step 3: Evaluate the model on the validation set\n",
    "metrics = model.val()  # Evaluate on the validation set\n",
    "print(f\"mAP50-95: {metrics.box.map}\")  # Print mean Average Precision (mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e0ade-bd7f-4ffb-a551-48bd6e2e1c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.94 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.91 ðŸš€ Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11l.pt, data=/mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/data.yaml, epochs=100, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=yolo_project, name=model_3.2.3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=yolo_project/model_3.2.3\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1412566  ultralytics.nn.modules.head.Detect           [2, [256, 512, 512]]          \n",
      "YOLO11l summary: 357 layers, 25,312,022 parameters, 25,312,006 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/train/labels.cache... 192 images, 0 back\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/valid/labels.cache... 17 images, 0 backgro\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to yolo_project/model_3.2.3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1myolo_project/model_3.2.3\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      5.29G      1.531      2.627      1.754         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [02:18<00:00,  5.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35     0.0874       0.65      0.141     0.0505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      5.46G      1.798       2.42      1.974         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [02:07<00:00,  5.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35     0.0082       0.85    0.00911    0.00391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      5.47G      1.905      2.486      2.066         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:57<00:00,  4.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35    0.00362       0.55    0.00631    0.00163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      5.46G      2.132      2.551      2.266         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:42<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35    0.00277      0.258    0.00227   0.000527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      5.45G      2.092      2.437      2.243         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35   0.000922     0.0917   0.000542   0.000322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      5.48G      2.033      2.327      2.197         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:43<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35    0.00584      0.717    0.00588    0.00208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      5.48G      1.952      2.259       2.13         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:35<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35   0.000386       0.05   0.000253   2.53e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      5.45G      1.847      2.088      2.078         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:41<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35     0.0111     0.0333     0.0024    0.00028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      5.45G      1.916      2.072      2.068         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:37<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35    0.00659      0.767    0.00732    0.00251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      5.46G      1.779      1.994      1.997         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:40<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35     0.0315      0.683     0.0378      0.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      5.45G      1.831      1.932      1.967         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:42<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35    0.00364      0.075    0.00213   0.000638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      5.46G      1.794      1.928       1.96         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:32<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35     0.0445      0.275     0.0225    0.00512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      5.46G      1.766       1.92      1.964         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:39<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.928      0.394      0.506      0.253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      5.46G      1.736      1.945      1.952         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:36<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.915      0.267       0.42      0.173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      5.46G      1.682      1.894       1.93         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.847        0.5      0.659      0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      5.45G      1.711       1.85      1.909         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:44<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.292      0.667      0.385      0.161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      5.46G      1.728      1.874      1.955         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:36<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.372        0.5      0.426      0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      5.46G      1.698      1.851       1.92         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:39<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.451      0.325      0.225      0.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      5.47G      1.635      1.814      1.873         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:44<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.358      0.408      0.372      0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      5.47G      1.594       1.73      1.818         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:46<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.676      0.475      0.549      0.263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      5.46G      1.609      1.764      1.842         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:39<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.606       0.65      0.507      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      5.46G      1.557      1.681      1.819         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:36<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35     0.0234      0.317     0.0257    0.00733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      5.45G      1.559      1.683      1.828         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:46<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.563      0.476      0.508      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      5.46G      1.533      1.623      1.816         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:36<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.882      0.508      0.711      0.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      5.45G      1.517      1.541      1.753         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:45<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.844      0.556      0.638      0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      5.46G      1.527      1.579      1.762         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:50<00:00,  4.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.707      0.606      0.718       0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      5.46G      1.478      1.516      1.667         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:46<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.786      0.725      0.792      0.421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      5.45G      1.483       1.58      1.756         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:52<00:00,  4.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.585       0.85      0.745      0.418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      5.45G      1.401      1.502      1.696         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:40<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.869        0.8      0.836      0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      5.47G      1.467      1.478      1.698         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:45<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.791      0.775      0.836      0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      5.45G      1.435      1.515      1.746         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:45<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.723        0.8      0.788      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      5.47G      1.447      1.484      1.694         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:53<00:00,  4.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.812      0.825      0.833      0.419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      5.45G      1.392      1.473      1.689         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:44<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.78      0.667       0.72      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      5.45G      1.335      1.372      1.619         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:52<00:00,  4.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.808      0.807      0.815      0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      5.46G      1.408      1.385      1.723         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:41<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.837      0.726      0.785      0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      5.45G      1.402      1.342       1.65         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:41<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.639      0.742      0.761       0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      5.45G      1.357      1.384      1.624         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:45<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.823       0.63      0.702      0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      5.45G      1.307      1.344      1.614         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:36<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.737       0.65      0.766      0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      5.45G      1.337      1.354      1.668         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:42<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.832      0.655      0.746      0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      5.46G      1.364      1.369       1.63         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:46<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.783      0.656      0.772      0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      5.45G      1.395      1.315      1.644         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:50<00:00,  4.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.832       0.83      0.874      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      5.46G       1.34      1.345      1.627         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:37<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.968      0.725      0.887      0.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      5.47G      1.285      1.272       1.54         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:39<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.818      0.846      0.857      0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      5.45G      1.332      1.345       1.62         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:37<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.841      0.768      0.809      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      5.45G      1.329      1.338       1.63         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:31<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.826       0.65      0.819      0.444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      5.45G      1.245      1.306      1.571         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.833      0.676      0.822       0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      5.46G      1.256      1.273      1.531         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:42<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.775      0.683      0.765      0.428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      5.46G      1.254      1.189      1.569         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.909      0.706      0.837      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      5.46G      1.295      1.249      1.596         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.887      0.742      0.801      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      5.45G      1.227      1.233      1.532         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:30<00:00,  3.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.847       0.75      0.866      0.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      5.45G      1.182      1.183      1.538         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:24<00:00,  3.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.817      0.811      0.861      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      5.45G      1.244       1.24      1.558         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:23<00:00,  3.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.795      0.842      0.878      0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      5.46G      1.213      1.128      1.546         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:28<00:00,  3.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.662      0.865       0.81      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      5.46G      1.242      1.206      1.566         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:27<00:00,  3.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.751      0.842      0.877      0.531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      5.47G      1.146      1.108      1.515         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:43<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.674      0.892      0.888      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      5.45G      1.158      1.112      1.522         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:47<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.829      0.875      0.903      0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      5.46G      1.205      1.105      1.489         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:35<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.822      0.843      0.881      0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      5.45G      1.142      1.076      1.475         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:36<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.929        0.8      0.889      0.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      5.46G      1.179       1.11      1.477         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:47<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.841      0.843       0.88      0.535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      5.45G      1.174      1.123      1.498         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:42<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.924      0.825      0.879      0.536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      5.45G      1.116      1.089      1.488         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:41<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.87      0.818      0.856      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      5.45G      1.121      1.091      1.496         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:33<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.924      0.775       0.86      0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      5.45G      1.159      1.068      1.511         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:35<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.803      0.781      0.845      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      5.46G      1.095      1.044      1.452         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:33<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.879      0.825      0.877      0.583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      5.46G      1.076      1.031      1.453         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:32<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.827      0.742      0.856      0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      5.46G       1.12      1.065      1.442         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:33<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.76      0.875      0.837      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      5.46G      1.059      1.021      1.424         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:42<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.817      0.842      0.897      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      5.45G      1.104      1.049      1.451         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:33<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.855      0.772       0.88      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      5.47G      1.073      1.003      1.439         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.901      0.802      0.927      0.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      5.47G      1.056     0.9639      1.396         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:32<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.75      0.875      0.925      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      5.47G      1.124      1.041      1.481         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:33<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.918      0.775      0.906      0.593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      5.45G      1.087      1.005      1.443         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:39<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.912      0.791      0.889      0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      5.45G       1.06     0.9889      1.411         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:28<00:00,  3.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.791       0.85      0.888      0.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      5.45G       1.06     0.9751      1.417         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:24<00:00,  3.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.898      0.825      0.903      0.584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      5.45G      0.981     0.9642      1.407         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:36<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.847      0.866      0.871      0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      5.45G      1.016     0.9559      1.429         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:31<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.77      0.875      0.833      0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      5.46G      1.031     0.9442      1.404         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:33<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.763      0.925      0.891      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      5.45G     0.9864     0.8755      1.376         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:26<00:00,  3.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.795      0.861      0.897      0.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      5.45G      1.027     0.9553      1.425         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:30<00:00,  3.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.818      0.875      0.893      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      5.45G       1.01     0.9259       1.39         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:28<00:00,  3.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.848      0.799      0.903      0.598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      5.45G     0.9364     0.9097      1.363         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:34<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.805      0.816      0.879       0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      5.45G     0.9592     0.8829       1.35         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:33<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.867      0.825      0.914      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      5.47G     0.9274     0.8411      1.343         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:33<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.947       0.85       0.94      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      5.48G     0.9371     0.8661       1.36         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:51<00:00,  4.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.946      0.875      0.941      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      5.46G     0.9652     0.9023      1.352         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:45<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35        0.9      0.875        0.9      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      5.47G     0.9567     0.8837      1.386         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:39<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.85        0.9      0.903      0.605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      5.46G     0.9544     0.8734      1.392         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:45<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.917      0.925      0.941       0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      5.46G     0.9298     0.8547      1.327         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:32<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.939      0.832      0.931      0.611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      5.45G     0.9198     0.8651      1.343         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:42<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.857      0.875      0.928      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      5.46G     0.9066     0.7958      1.295         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:50<00:00,  4.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.848      0.872      0.911      0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      5.45G      0.803     0.7163      1.276         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:46<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.914        0.8      0.917       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      5.46G     0.7915     0.7067      1.272         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:47<00:00,  4.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.925       0.85      0.931      0.626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      5.46G     0.7903     0.6618      1.276         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:44<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.831      0.875      0.934      0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      5.47G     0.7242      0.648      1.181         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:37<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.874      0.875      0.942       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      5.46G      0.724     0.6327      1.204         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:40<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.795      0.898       0.93      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      5.45G     0.7096     0.6116      1.214         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:38<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.816       0.85      0.919      0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      5.46G     0.6781     0.5776      1.177         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:31<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.852      0.842      0.921       0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      5.47G     0.7142     0.5972      1.219         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:40<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.896      0.875      0.928      0.664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      5.47G     0.6899     0.5806      1.202         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:31<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35       0.88      0.875      0.927       0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      5.45G     0.6825     0.5648      1.188         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [01:35<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.886      0.879      0.928       0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 2.919 hours.\n",
      "Optimizer stripped from yolo_project/model_3.2.3/weights/last.pt, 51.2MB\n",
      "Optimizer stripped from yolo_project/model_3.2.3/weights/best.pt, 51.2MB\n",
      "\n",
      "Validating yolo_project/model_3.2.3/weights/best.pt...\n",
      "Ultralytics 8.3.91 ðŸš€ Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "YOLO11l summary (fused): 190 layers, 25,280,854 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.808      0.904      0.911      0.637\n",
      "                 human         15         15      0.886          1      0.995      0.802\n",
      "                 robot         17         20      0.729      0.809      0.828      0.473\n",
      "Speed: 0.3ms preprocess, 130.0ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1myolo_project/model_3.2.3\u001b[0m\n",
      "Ultralytics 8.3.91 ðŸš€ Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "YOLO11l summary (fused): 190 layers, 25,280,854 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/valid/labels.cache... 17 images, 0 backgro\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:16<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         17         35      0.808      0.907      0.911       0.64\n",
      "                 human         15         15      0.886          1      0.995      0.802\n",
      "                 robot         17         20      0.731      0.814      0.828      0.478\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolo11l.pt\")  # Load YOLOv8n (smallest model)\n",
    "\n",
    "# Step 2: Train the model\n",
    "#\"C:\\Users\\adnan\\Desktop\\urfikhan\\Final_anotated_data\\Model_1\\data.yaml\"\n",
    "results=model.train(\n",
    "    data= \"/mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/data.yaml\",  # Path to your data.yaml file\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    lr0=0.001,  # Reduced learning rate\n",
    "    #accumulate=2,\n",
    "    device=0,# Gradient accumulation\n",
    "    amp=True,  # Mixed precision training\n",
    "    augment=True,  # Data augmentation\n",
    "    #class_weights=[1.0, 1.5],  # Class weights for imbalance\n",
    "    project=\"yolo_project\",\n",
    "    name=\"model_3.2.3\"\n",
    ")\n",
    "\n",
    "\n",
    "# Step 3: Evaluate the model on the validation set\n",
    "metrics = model.val()  # Evaluate on the validation set\n",
    "print(f\"mAP50-95: {metrics.box.map}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88f492a-ed17-4dbc-9fa9-724b5c5fc73f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'YOLO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 1: Load a pretrained model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Choose from: yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo11l.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Load YOLOv8n (smallest model)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Step 2: Train the model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#\"C:\\Users\\adnan\\Desktop\\urfikhan\\Final_anotated_data\\Model_1\\data.yaml\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m      8\u001b[0m     data\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_1/data.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Path to your data.yaml file\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,                \u001b[38;5;66;03m# Number of training epochs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_1\u001b[39m\u001b[38;5;124m\"\u001b[39m     \u001b[38;5;66;03m# Name of the training run (optional)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'YOLO' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: Load a pretrained model\n",
    "# Choose from: yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt\n",
    "model = YOLO(\"yolo11l.pt\")  # Load YOLOv8n (smallest model)\n",
    "\n",
    "# Step 2: Train the model\n",
    "#\"C:\\Users\\adnan\\Desktop\\urfikhan\\Final_anotated_data\\Model_1\\data.yaml\"\n",
    "results = model.train(\n",
    "    data= \"/mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_1/data.yaml\",  # Path to your data.yaml file\n",
    "    epochs=30,                # Number of training epochs\n",
    "    imgsz=640,                # Image size (640x640)\n",
    "    batch=8,                 # Batch size (adjust based on GPU memory)\n",
    "    device=0,                 # Use GPU (0) or CPU (-1)\n",
    "    name=\"model_1\"     # Name of the training run (optional)\n",
    ")\n",
    "\n",
    "# Step 3: Evaluate the model on the validation set\n",
    "metrics = model.val()  # Evaluate on the validation set\n",
    "print(f\"mAP50-95: {metrics.box.map}\")  # Print mean Average Precision (mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78305b97-ebcf-4801-b0ef-5d3a8a589147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/adnan/Desktop/urfikhan/input_videos\n",
      "v1_svideo_detected1.mp4\n",
      "/mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_svideo_detected1.mp4\n",
      "\n",
      "\n",
      "WARNING âš ï¸ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 94.7ms\n",
      "video 1/1 (frame 2/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.6ms\n",
      "video 1/1 (frame 3/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 19.1ms\n",
      "video 1/1 (frame 4/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.9ms\n",
      "video 1/1 (frame 5/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.7ms\n",
      "video 1/1 (frame 6/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 19.5ms\n",
      "video 1/1 (frame 7/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.0ms\n",
      "video 1/1 (frame 8/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.4ms\n",
      "video 1/1 (frame 9/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.2ms\n",
      "video 1/1 (frame 10/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 57.4ms\n",
      "video 1/1 (frame 11/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 31.6ms\n",
      "video 1/1 (frame 12/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 26.7ms\n",
      "video 1/1 (frame 13/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.4ms\n",
      "video 1/1 (frame 14/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 20.7ms\n",
      "video 1/1 (frame 15/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.1ms\n",
      "video 1/1 (frame 16/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.3ms\n",
      "video 1/1 (frame 17/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 30.9ms\n",
      "video 1/1 (frame 18/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 19.3ms\n",
      "video 1/1 (frame 19/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 37.9ms\n",
      "video 1/1 (frame 20/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 17.5ms\n",
      "video 1/1 (frame 21/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 17.5ms\n",
      "video 1/1 (frame 22/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.4ms\n",
      "video 1/1 (frame 23/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.7ms\n",
      "video 1/1 (frame 24/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.9ms\n",
      "video 1/1 (frame 25/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.8ms\n",
      "video 1/1 (frame 26/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 20.0ms\n",
      "video 1/1 (frame 27/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 36.3ms\n",
      "video 1/1 (frame 28/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 19.4ms\n",
      "video 1/1 (frame 29/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 19.7ms\n",
      "video 1/1 (frame 30/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 20.1ms\n",
      "video 1/1 (frame 31/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 21.6ms\n",
      "video 1/1 (frame 32/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 21.0ms\n",
      "video 1/1 (frame 33/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 21.6ms\n",
      "video 1/1 (frame 34/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 21.7ms\n",
      "video 1/1 (frame 35/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 42.5ms\n",
      "video 1/1 (frame 36/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 21.7ms\n",
      "video 1/1 (frame 37/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 22.2ms\n",
      "video 1/1 (frame 38/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 22.5ms\n",
      "video 1/1 (frame 39/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 22.0ms\n",
      "video 1/1 (frame 40/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 22.2ms\n",
      "video 1/1 (frame 41/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 22.4ms\n",
      "video 1/1 (frame 42/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 22.4ms\n",
      "video 1/1 (frame 43/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 22.3ms\n",
      "video 1/1 (frame 44/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 22.5ms\n",
      "video 1/1 (frame 45/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 robot, 22.5ms\n",
      "video 1/1 (frame 46/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 robot, 46.5ms\n",
      "video 1/1 (frame 47/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 22.2ms\n",
      "video 1/1 (frame 48/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 22.4ms\n",
      "video 1/1 (frame 49/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 22.7ms\n",
      "video 1/1 (frame 50/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 23.3ms\n",
      "video 1/1 (frame 51/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 23.4ms\n",
      "video 1/1 (frame 52/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 23.2ms\n",
      "video 1/1 (frame 53/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 23.9ms\n",
      "video 1/1 (frame 54/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 24.0ms\n",
      "video 1/1 (frame 55/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 23.6ms\n",
      "video 1/1 (frame 56/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 24.3ms\n",
      "video 1/1 (frame 57/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 23.6ms\n",
      "video 1/1 (frame 58/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 23.6ms\n",
      "video 1/1 (frame 59/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 40.3ms\n",
      "video 1/1 (frame 60/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 24.4ms\n",
      "video 1/1 (frame 61/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 24.5ms\n",
      "video 1/1 (frame 62/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 24.6ms\n",
      "video 1/1 (frame 63/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 24.5ms\n",
      "video 1/1 (frame 64/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 48.2ms\n",
      "video 1/1 (frame 65/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 24.6ms\n",
      "video 1/1 (frame 66/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 24.4ms\n",
      "video 1/1 (frame 67/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 24.5ms\n",
      "video 1/1 (frame 68/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 24.4ms\n",
      "video 1/1 (frame 69/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 24.7ms\n",
      "video 1/1 (frame 70/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 24.8ms\n",
      "video 1/1 (frame 71/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 43.6ms\n",
      "video 1/1 (frame 72/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 25.0ms\n",
      "video 1/1 (frame 73/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 25.1ms\n",
      "video 1/1 (frame 74/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 25.2ms\n",
      "video 1/1 (frame 75/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 25.2ms\n",
      "video 1/1 (frame 76/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 25.5ms\n",
      "video 1/1 (frame 77/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 25.8ms\n",
      "video 1/1 (frame 78/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 25.4ms\n",
      "video 1/1 (frame 79/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 29.7ms\n",
      "video 1/1 (frame 80/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 39.2ms\n",
      "video 1/1 (frame 81/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 100.6ms\n",
      "video 1/1 (frame 82/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 1 robot, 102.1ms\n",
      "video 1/1 (frame 83/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 1 robot, 90.2ms\n",
      "video 1/1 (frame 84/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 1 robot, 85.0ms\n",
      "video 1/1 (frame 85/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 1 robot, 83.2ms\n",
      "video 1/1 (frame 86/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 1 robot, 191.8ms\n",
      "video 1/1 (frame 87/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 103.0ms\n",
      "video 1/1 (frame 88/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 36.1ms\n",
      "video 1/1 (frame 89/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 17.7ms\n",
      "video 1/1 (frame 90/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 17.5ms\n",
      "video 1/1 (frame 91/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 17.6ms\n",
      "video 1/1 (frame 92/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 18.0ms\n",
      "video 1/1 (frame 93/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 19.2ms\n",
      "video 1/1 (frame 94/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 17.8ms\n",
      "video 1/1 (frame 95/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 18.6ms\n",
      "video 1/1 (frame 96/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 19.5ms\n",
      "video 1/1 (frame 97/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 48.0ms\n",
      "video 1/1 (frame 98/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.2ms\n",
      "video 1/1 (frame 99/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 18.2ms\n",
      "video 1/1 (frame 100/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 26.6ms\n",
      "video 1/1 (frame 101/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 36.6ms\n",
      "video 1/1 (frame 102/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 44.1ms\n",
      "video 1/1 (frame 103/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 28.1ms\n",
      "video 1/1 (frame 104/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 robot, 45.0ms\n",
      "video 1/1 (frame 105/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 robot, 36.3ms\n",
      "video 1/1 (frame 106/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 40.6ms\n",
      "video 1/1 (frame 107/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 31.9ms\n",
      "video 1/1 (frame 108/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 34.2ms\n",
      "video 1/1 (frame 109/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 43.7ms\n",
      "video 1/1 (frame 110/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 33.7ms\n",
      "video 1/1 (frame 111/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 29.5ms\n",
      "video 1/1 (frame 112/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 47.1ms\n",
      "video 1/1 (frame 113/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 31.3ms\n",
      "video 1/1 (frame 114/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 39.5ms\n",
      "video 1/1 (frame 115/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 33.4ms\n",
      "video 1/1 (frame 116/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 46.3ms\n",
      "video 1/1 (frame 117/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 93.0ms\n",
      "video 1/1 (frame 118/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 83.4ms\n",
      "video 1/1 (frame 119/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 79.5ms\n",
      "video 1/1 (frame 120/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 26.1ms\n",
      "video 1/1 (frame 121/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 25.3ms\n",
      "video 1/1 (frame 122/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 26.5ms\n",
      "video 1/1 (frame 123/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 26.5ms\n",
      "video 1/1 (frame 124/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 27.3ms\n",
      "video 1/1 (frame 125/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 56.9ms\n",
      "video 1/1 (frame 126/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 55.6ms\n",
      "video 1/1 (frame 127/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 60.2ms\n",
      "video 1/1 (frame 128/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 61.4ms\n",
      "video 1/1 (frame 129/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 46.1ms\n",
      "video 1/1 (frame 130/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 46.1ms\n",
      "video 1/1 (frame 131/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 40.5ms\n",
      "video 1/1 (frame 132/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 81.5ms\n",
      "video 1/1 (frame 133/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 77.4ms\n",
      "video 1/1 (frame 134/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 76.7ms\n",
      "video 1/1 (frame 135/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 23.0ms\n",
      "video 1/1 (frame 136/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 53.8ms\n",
      "video 1/1 (frame 137/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 23.7ms\n",
      "video 1/1 (frame 138/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 30.4ms\n",
      "video 1/1 (frame 139/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 22.2ms\n",
      "video 1/1 (frame 140/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 30.5ms\n",
      "video 1/1 (frame 141/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 22.5ms\n",
      "video 1/1 (frame 142/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 22.8ms\n",
      "video 1/1 (frame 143/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 23.3ms\n",
      "video 1/1 (frame 144/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 22.5ms\n",
      "video 1/1 (frame 145/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 92.0ms\n",
      "video 1/1 (frame 146/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 93.0ms\n",
      "video 1/1 (frame 147/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 79.8ms\n",
      "video 1/1 (frame 148/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 92.0ms\n",
      "video 1/1 (frame 149/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 (no detections), 79.9ms\n",
      "video 1/1 (frame 150/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 80.0ms\n",
      "video 1/1 (frame 151/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 80.3ms\n",
      "video 1/1 (frame 152/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 170.6ms\n",
      "video 1/1 (frame 153/316) /mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4: 384x640 1 human, 101.7ms\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Step 1: Load your trained YOLOv8 model\n",
    "model = YOLO(\"runs/detect/yolov_mixed_data_8m3/weights/best.pt\")  # Replace with the path to your trained model\n",
    "\n",
    "# Step 2: Define the input video path\n",
    "input_video_path = \"/mnt/c/Users/adnan/Desktop/urfikhan/input_videos/v1_s.mp4\"  # Path to the input video\n",
    "\n",
    "\n",
    "# Step 3: Define the output video path (in the same folder as the input video)\n",
    "output_video_folder = os.path.dirname(input_video_path)\n",
    "print(output_video_folder)# Get the folder of the input video\n",
    "output_video_name = os.path.splitext(os.path.basename(input_video_path))[0] + \"video_detected1.mp4\"\n",
    "print(output_video_name)\n",
    "output_video_path = os.path.join(output_video_folder, output_video_name)\n",
    "print(output_video_path)\n",
    "# Step 4: Perform object detection on the video\n",
    "results = model.predict(\n",
    "    source=input_video_path,  # Input video path\n",
    "    conf=0.5,  # Confidence threshold (adjust as needed)\n",
    "    save=True,  # Save the output video\n",
    "    project=output_video_folder,  # Save in the same folder as the input video\n",
    "    name=output_video_name,  # Name of the output video\n",
    "    exist_ok=True,  # Overwrite if the output file already exists\n",
    ")\n",
    "\n",
    "# Step 5: Print the path to the saved output video\n",
    "print(f\"Input video: {input_video_path}\")\n",
    "print(f\"Output video saved at: {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f1aec6-d675-4eee-a709-c26bb91ebfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.93 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.91 ðŸš€ Python-3.9.21 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Ti Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11l.pt, data=/mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/data.yaml, epochs=40, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=model_3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/model_3\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1412566  ultralytics.nn.modules.head.Detect           [2, [256, 512, 512]]          \n",
      "YOLO11l summary: 357 layers, 25,312,022 parameters, 25,312,006 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/train/labels... 168 images, 0 background\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/valid/labels... 16 images, 0 backgrounds, \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adnan/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/adnan/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float64'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n",
      "/home/adnan/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/numpy/core/getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "/home/adnan/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/model_3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/model_3\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/40      5.28G      1.428       2.46      1.737         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:48<00:00,  5.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.495      0.384      0.427      0.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/40      5.45G      1.714       2.35      1.937         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:21<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.108      0.522     0.0861      0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/40       5.4G       1.93      2.621      2.153         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:28<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/40      5.46G      2.006      2.471      2.248         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:26<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/40       5.4G      1.899      2.363      2.116         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:32<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32     0.0181      0.584     0.0122    0.00302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/40      5.45G      1.963      2.302      2.182         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:23<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32    0.00059     0.0882   0.000666   0.000138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/40      5.47G      1.909      2.125      2.082         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:21<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32     0.0042      0.429    0.00564    0.00144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/40       5.4G      1.889      2.093      2.068         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:34<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.509        0.4     0.0195    0.00395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/40      5.45G      1.895      2.033      2.061         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:25<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.106      0.329     0.0632     0.0182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/40      5.46G      1.782      1.887      1.936         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:26<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.645      0.333      0.252     0.0967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/40      5.45G      1.759      1.838      1.927         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:37<00:00,  4.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.563      0.647      0.715      0.292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/40      5.45G      1.764      1.832      1.964         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:26<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.755       0.45      0.486      0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/40      5.45G      1.672      1.745      1.888         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:31<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.308      0.391      0.304      0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/40      5.45G      1.645      1.731       1.87         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:29<00:00,  4.2\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32       0.54      0.646      0.616      0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/40      5.46G      1.573      1.693      1.834         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:33<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.587      0.678      0.653      0.406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/40      5.41G      1.566      1.664      1.827         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:26<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.831      0.598      0.694       0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/40      5.46G      1.533       1.64      1.819         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:20<00:00,  3.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.499      0.644      0.661      0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/40      5.47G      1.519      1.524      1.803         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:23<00:00,  3.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.692      0.647       0.63      0.328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/40      5.46G      1.475      1.475       1.76         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:32<00:00,  4.4\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.612      0.757      0.783      0.377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/40      5.45G      1.528      1.516      1.803         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:24<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.718      0.706      0.767      0.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/40      5.46G      1.418      1.479      1.725         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:18<00:00,  3.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.736      0.706      0.791      0.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/40      5.45G      1.438      1.435      1.742         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:26<00:00,  4.1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.745      0.807       0.85      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/40      5.45G      1.412       1.38      1.711         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:24<00:00,  4.0\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.753      0.812      0.816      0.435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/40       5.4G      1.469      1.417      1.767         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [01:30<00:00,  4.3\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         16         32      0.885      0.673      0.853      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/40      5.46G      1.351      1.354      1.668         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [1:44:53<00:00, 29\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:01<?,\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/engine/validator.py:214\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dt[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 214\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Loss\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/nn/tasks.py:114\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/nn/tasks.py:132\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/nn/tasks.py:153\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 153\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    154\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/nn/modules/block.py:301\u001b[0m, in \u001b[0;36mC2f.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    300\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 301\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/nn/modules/block.py:301\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    300\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 301\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/nn/modules/block.py:336\u001b[0m, in \u001b[0;36mC3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through the CSP bottleneck with 3 convolutions.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv3(torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(x)), \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/nn/modules/block.py:476\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Apply bottleneck with optional shortcut connection.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x))\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/nn/modules/conv.py:79\u001b[0m, in \u001b[0;36mConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mApply convolution, batch normalization and activation to input tensor.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/nn/functional.py:2822\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2820\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2823\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2830\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2832\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo11l.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Load YOLOv8n (smallest model)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Step 2: Train the model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#\"C:\\Users\\adnan\\Desktop\\urfikhan\\Final_anotated_data\\Model_1\\data.yaml\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/data.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Path to your data.yaml file\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Number of training epochs\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Image size (640x640)\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# Batch size (adjust based on GPU memory)\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# Use GPU (0) or CPU (-1)\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Name of the training run (optional)\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Step 3: Evaluate the model on the validation set\u001b[39;00m\n\u001b[1;32m     17\u001b[0m metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mval()  \u001b[38;5;66;03m# Evaluate on the validation set\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/engine/model.py:791\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/engine/trainer.py:211\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/engine/trainer.py:436\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mval \u001b[38;5;129;01mor\u001b[39;00m final_epoch \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper\u001b[38;5;241m.\u001b[39mpossible_stop \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop:\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_metrics(metrics\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_loss_items(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr})\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness) \u001b[38;5;129;01mor\u001b[39;00m final_epoch\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/engine/trainer.py:627\u001b[0m, in \u001b[0;36mBaseTrainer.validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    621\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;124;03m    Run validation on test set using self.validator.\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \n\u001b[1;32m    624\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;124;03m        (tuple): A tuple containing metrics dictionary and fitness score.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 627\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# use loss as fitness measure if not found\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;241m<\u001b[39m fitness:\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/engine/validator.py:214\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dt[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 214\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model(batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg\u001b[39m\u001b[38;5;124m\"\u001b[39m], augment\u001b[38;5;241m=\u001b[39maugment)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dt[\u001b[38;5;241m2\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/utils/ops.py:52\u001b[0m, in \u001b[0;36mProfile.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mtype\u001b[39m, value, traceback):  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Stop timing.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart  \u001b[38;5;66;03m# delta-time\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/utils/ops.py:62\u001b[0m, in \u001b[0;36mProfile.time\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get current time.\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda:\n\u001b[0;32m---> 62\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time\u001b[38;5;241m.\u001b[39mperf_counter()\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/cuda/__init__.py:985\u001b[0m, in \u001b[0;36msynchronize\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    983\u001b[0m _lazy_init()\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[0;32m--> 985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 1: Load a pretrained model\n",
    "# Choose from: yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt\n",
    "model = YOLO(\"yolo11l.pt\")  # Load YOLOv8n (smallest model)\n",
    "\n",
    "# Step 2: Train the model\n",
    "#\"C:\\Users\\adnan\\Desktop\\urfikhan\\Final_anotated_data\\Model_1\\data.yaml\"\n",
    "results = model.train(\n",
    "    data= \"/mnt/c/Users/adnan/Desktop/urfikhan/Final_anotated_data/Model_3/data.yaml\",  # Path to your data.yaml file\n",
    "    epochs=40,                # Number of training epochs\n",
    "    imgsz=640,                # Image size (640x640)\n",
    "    batch=8,                 # Batch size (adjust based on GPU memory)\n",
    "    device=0,                 # Use GPU (0) or CPU (-1)\n",
    "    name=\"model_3\"     # Name of the training run (optional)\n",
    ")\n",
    "\n",
    "# Step 3: Evaluate the model on the validation set\n",
    "metrics = model.val()  # Evaluate on the validation set\n",
    "print(f\"mAP50-95: {metrics.box.map}\")  # Print mean Average Precision (mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdba65c-4dd4-40b9-a4da-e5a35d004eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/adnan/Desktop/urfikhan\n",
      "video2video_detected2.mp4\n",
      "/mnt/c/Users/adnan/Desktop/urfikhan/video2video_detected2.mp4\n",
      "\n",
      "\n",
      "WARNING âš ï¸ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 69.8ms\n",
      "video 1/1 (frame 2/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 3/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15.2ms\n",
      "video 1/1 (frame 4/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15.2ms\n",
      "video 1/1 (frame 5/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 6/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 7/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 8/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 9/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 10/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 11/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 12/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 13/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 14/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 16.3ms\n",
      "video 1/1 (frame 15/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 16/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 17/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 18/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 19/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 20/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 21/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 22/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 23/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 24/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 25/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 26/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 27/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 28/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 29/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 30/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 31/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 32/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 33/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 34/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 35/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 36/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 37/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 38/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 39/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 40/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 41/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 42/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 43/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 44/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 45/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 46/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 47/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 48/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 49/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 50/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 51/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 52/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 53/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 54/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 55/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 24.9ms\n",
      "video 1/1 (frame 56/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 28.7ms\n",
      "video 1/1 (frame 57/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 24.6ms\n",
      "video 1/1 (frame 58/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 25.6ms\n",
      "video 1/1 (frame 59/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 24.3ms\n",
      "video 1/1 (frame 60/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 61/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 62/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 63/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 64/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 65/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 66/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 67/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 68/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 69/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 70/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 71/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 72/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 73/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 74/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 75/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 76/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 77/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 78/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 79/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 80/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 81/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 82/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 83/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 84/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 85/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 86/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 87/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 88/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 89/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 90/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 91/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 92/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 93/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 94/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 95/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 96/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 97/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 98/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 99/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 100/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 101/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 102/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 103/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 104/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 105/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 106/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 107/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 108/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 109/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 110/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 111/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 112/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 113/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 114/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 115/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 116/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 117/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 118/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 119/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 120/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 121/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 122/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 123/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 124/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 125/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 126/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 127/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 128/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 129/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 130/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 131/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 132/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 133/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 134/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 135/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 136/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 137/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 138/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 139/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 140/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 141/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 142/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 143/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 144/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 145/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 146/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 341.7ms\n",
      "video 1/1 (frame 147/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 556.7ms\n",
      "video 1/1 (frame 148/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12295.3ms\n",
      "video 1/1 (frame 149/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 257.2ms\n",
      "video 1/1 (frame 150/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 9366.6ms\n",
      "video 1/1 (frame 151/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 28382.5ms\n",
      "video 1/1 (frame 152/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 248.0ms\n",
      "video 1/1 (frame 153/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 9880.0ms\n",
      "video 1/1 (frame 154/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15379.4ms\n",
      "video 1/1 (frame 155/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 10083.8ms\n",
      "video 1/1 (frame 156/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 177.0ms\n",
      "video 1/1 (frame 157/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15.3ms\n",
      "video 1/1 (frame 158/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 159/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15.2ms\n",
      "video 1/1 (frame 160/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 161/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15.2ms\n",
      "video 1/1 (frame 162/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 17.1ms\n",
      "video 1/1 (frame 163/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.3ms\n",
      "video 1/1 (frame 164/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.3ms\n",
      "video 1/1 (frame 165/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 166/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 167/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 168/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.3ms\n",
      "video 1/1 (frame 169/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 170/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 171/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 172/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 173/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 174/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 175/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 176/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 177/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 178/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 179/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 180/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 181/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 182/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 183/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 20.8ms\n",
      "video 1/1 (frame 184/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 185/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 186/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 187/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 188/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 189/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 190/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 191/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 192/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 193/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 194/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 29.1ms\n",
      "video 1/1 (frame 195/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 196/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 197/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 198/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 199/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 200/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 201/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 202/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 203/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 204/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 205/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 206/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 207/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 208/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 209/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 210/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 211/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 212/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 213/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 214/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 215/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 216/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 217/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 218/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 219/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 220/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 221/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 222/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 223/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 224/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 225/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 226/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 227/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 228/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 229/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 19.5ms\n",
      "video 1/1 (frame 230/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 231/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 232/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 233/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 234/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 235/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 236/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 18.4ms\n",
      "video 1/1 (frame 237/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 18.9ms\n",
      "video 1/1 (frame 238/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 239/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 240/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 241/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 242/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 243/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 244/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 245/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 246/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 247/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 248/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 249/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 6149.1ms\n",
      "video 1/1 (frame 250/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 238.6ms\n",
      "video 1/1 (frame 251/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 5846.0ms\n",
      "video 1/1 (frame 252/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 307.6ms\n",
      "video 1/1 (frame 253/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 310.0ms\n",
      "video 1/1 (frame 254/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 2579.4ms\n",
      "video 1/1 (frame 255/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 10871.3ms\n",
      "video 1/1 (frame 256/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 1496.8ms\n",
      "video 1/1 (frame 257/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13661.4ms\n",
      "video 1/1 (frame 258/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 22768.6ms\n",
      "video 1/1 (frame 259/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 280.5ms\n",
      "video 1/1 (frame 260/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 16366.7ms\n",
      "video 1/1 (frame 261/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 35768.0ms\n",
      "video 1/1 (frame 262/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 18448.9ms\n",
      "video 1/1 (frame 263/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 24358.3ms\n",
      "video 1/1 (frame 264/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 26675.3ms\n",
      "video 1/1 (frame 265/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 273.3ms\n",
      "video 1/1 (frame 266/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 8455.4ms\n",
      "video 1/1 (frame 267/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 20876.6ms\n",
      "WARNING âš ï¸ NMS time limit 2.050s exceeded\n",
      "video 1/1 (frame 268/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 32211.3ms\n",
      "WARNING âš ï¸ NMS time limit 2.050s exceeded\n",
      "video 1/1 (frame 269/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 44130.8ms\n",
      "WARNING âš ï¸ NMS time limit 2.050s exceeded\n",
      "video 1/1 (frame 270/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 33963.4ms\n",
      "WARNING âš ï¸ NMS time limit 2.050s exceeded\n",
      "video 1/1 (frame 271/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 32900.5ms\n",
      "WARNING âš ï¸ NMS time limit 2.050s exceeded\n",
      "video 1/1 (frame 272/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 38858.6ms\n",
      "WARNING âš ï¸ NMS time limit 2.050s exceeded\n",
      "video 1/1 (frame 273/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 175810.0ms\n",
      "video 1/1 (frame 274/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 474194.6ms\n",
      "video 1/1 (frame 275/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 175.2ms\n",
      "video 1/1 (frame 276/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 22.8ms\n",
      "video 1/1 (frame 277/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 278/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 279/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 280/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 281/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 282/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 283/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 284/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 285/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 286/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 287/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 288/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 289/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 290/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 291/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 292/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 293/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 294/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 295/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 296/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 297/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 298/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 299/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 300/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 301/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 302/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 303/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 304/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 305/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 306/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 307/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 308/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 309/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 310/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 311/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 312/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 313/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 314/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 315/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 316/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 317/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 318/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 319/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 320/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 321/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 322/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 323/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 324/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 325/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 326/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 4586.7ms\n",
      "video 1/1 (frame 327/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 1175.2ms\n",
      "video 1/1 (frame 328/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 240.6ms\n",
      "video 1/1 (frame 329/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 197.5ms\n",
      "video 1/1 (frame 330/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 266.1ms\n",
      "video 1/1 (frame 331/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 8375.0ms\n",
      "video 1/1 (frame 332/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 2161.2ms\n",
      "video 1/1 (frame 333/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 29264.3ms\n",
      "WARNING âš ï¸ NMS time limit 2.050s exceeded\n",
      "video 1/1 (frame 334/1222) /mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4: 384x640 1 human, 1 robot, 31264.1ms\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Step 1: Load your trained YOLOv8 model\n",
    "model = YOLO(\"runs/detect/custom_yolov8m/weights/best.pt\")  # Replace with the path to your trained model\n",
    "\n",
    "# Step 2: Define the input video path\n",
    "input_video_path = \"/mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4\"  # Path to the input video\n",
    "\n",
    "\n",
    "# Step 3: Define the output video path (in the same folder as the input video)\n",
    "output_video_folder = os.path.dirname(input_video_path)\n",
    "print(output_video_folder)# Get the folder of the input video\n",
    "output_video_name = os.path.splitext(os.path.basename(input_video_path))[0] + \"video_detected2\"\n",
    "print(output_video_name)\n",
    "output_video_path = os.path.join(output_video_folder, output_video_name)\n",
    "print(output_video_path)\n",
    "# Step 4: Perform object detection on the video\n",
    "results = model.predict(\n",
    "    source=input_video_path,  # Input video path\n",
    "    conf=0.5,  # Confidence threshold (adjust as needed)\n",
    "    save=True,  # Save the output video\n",
    "    project=output_video_folder,  # Save in the same folder as the input video\n",
    "    name=output_video_name,  # Name of the output video\n",
    "    exist_ok=True,  # Overwrite if the output file already exists\n",
    ")\n",
    "\n",
    "# Step 5: Print the path to the saved output video\n",
    "print(f\"Input video: {input_video_path}\")\n",
    "print(f\"Output video saved at: {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78aedd6-b8ac-4c35-915d-ff99760446b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Perform object detection on the video\n",
    "results = model.predict(\n",
    "    source=input_video_path,  # Input video path\n",
    "    conf=0.5,  # Confidence threshold (adjust as needed)\n",
    "    save=True,  # Save the output video\n",
    "    project=output_video_folder,  # Save in the same folder as the input video\n",
    "    name=output_video_name,  # Name of the output video\n",
    "    exist_ok=True,  # Overwrite if the output file already exists\n",
    ")\n",
    "\n",
    "# Step 5: Print the path to the saved output video\n",
    "print(f\"Input video: {input_video_path}\")\n",
    "print(f\"Output video saved at: {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a27ed61-84cd-4043-a1ab-4c7e8f499bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING âš ï¸ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 96.5ms\n",
      "video 1/1 (frame 2/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 66.2ms\n",
      "video 1/1 (frame 3/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 66.3ms\n",
      "video 1/1 (frame 4/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 30.0ms\n",
      "video 1/1 (frame 5/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 30.0ms\n",
      "video 1/1 (frame 6/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 30.3ms\n",
      "video 1/1 (frame 7/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 28.8ms\n",
      "video 1/1 (frame 8/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 28.7ms\n",
      "video 1/1 (frame 9/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 29.6ms\n",
      "video 1/1 (frame 10/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 9.6ms\n",
      "video 1/1 (frame 11/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.0ms\n",
      "video 1/1 (frame 12/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 11.0ms\n",
      "video 1/1 (frame 13/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.0ms\n",
      "video 1/1 (frame 14/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 10.6ms\n",
      "video 1/1 (frame 15/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.5ms\n",
      "video 1/1 (frame 16/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.6ms\n",
      "video 1/1 (frame 17/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.2ms\n",
      "video 1/1 (frame 18/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.7ms\n",
      "video 1/1 (frame 19/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.0ms\n",
      "video 1/1 (frame 20/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.6ms\n",
      "video 1/1 (frame 21/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.1ms\n",
      "video 1/1 (frame 22/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.5ms\n",
      "video 1/1 (frame 23/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.0ms\n",
      "video 1/1 (frame 24/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 11.8ms\n",
      "video 1/1 (frame 25/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.7ms\n",
      "video 1/1 (frame 26/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.3ms\n",
      "video 1/1 (frame 27/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.2ms\n",
      "video 1/1 (frame 28/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 19.0ms\n",
      "video 1/1 (frame 29/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.8ms\n",
      "video 1/1 (frame 30/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.3ms\n",
      "video 1/1 (frame 31/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.2ms\n",
      "video 1/1 (frame 32/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.2ms\n",
      "video 1/1 (frame 33/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 10.5ms\n",
      "video 1/1 (frame 34/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 11.8ms\n",
      "video 1/1 (frame 35/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.3ms\n",
      "video 1/1 (frame 36/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 14.3ms\n",
      "video 1/1 (frame 37/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 10.4ms\n",
      "video 1/1 (frame 38/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 15.4ms\n",
      "video 1/1 (frame 39/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.9ms\n",
      "video 1/1 (frame 40/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 11.7ms\n",
      "video 1/1 (frame 41/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.2ms\n",
      "video 1/1 (frame 42/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.8ms\n",
      "video 1/1 (frame 43/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 39.3ms\n",
      "video 1/1 (frame 44/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 36.5ms\n",
      "video 1/1 (frame 45/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 10.6ms\n",
      "video 1/1 (frame 46/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.5ms\n",
      "video 1/1 (frame 47/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 19.4ms\n",
      "video 1/1 (frame 48/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.9ms\n",
      "video 1/1 (frame 49/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 51.7ms\n",
      "video 1/1 (frame 50/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 37.9ms\n",
      "video 1/1 (frame 51/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.3ms\n",
      "video 1/1 (frame 52/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 37.9ms\n",
      "video 1/1 (frame 53/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 10.2ms\n",
      "video 1/1 (frame 54/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.1ms\n",
      "video 1/1 (frame 55/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.4ms\n",
      "video 1/1 (frame 56/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 11.6ms\n",
      "video 1/1 (frame 57/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.0ms\n",
      "video 1/1 (frame 58/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 11.6ms\n",
      "video 1/1 (frame 59/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.6ms\n",
      "video 1/1 (frame 60/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 14.0ms\n",
      "video 1/1 (frame 61/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.7ms\n",
      "video 1/1 (frame 62/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.3ms\n",
      "video 1/1 (frame 63/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.9ms\n",
      "video 1/1 (frame 64/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.7ms\n",
      "video 1/1 (frame 65/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 15.5ms\n",
      "video 1/1 (frame 66/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.6ms\n",
      "video 1/1 (frame 67/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.5ms\n",
      "video 1/1 (frame 68/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 11.8ms\n",
      "video 1/1 (frame 69/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.1ms\n",
      "video 1/1 (frame 70/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.8ms\n",
      "video 1/1 (frame 71/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 11.9ms\n",
      "video 1/1 (frame 72/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 11.9ms\n",
      "video 1/1 (frame 73/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 11.9ms\n",
      "video 1/1 (frame 74/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 11.7ms\n",
      "video 1/1 (frame 75/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.0ms\n",
      "video 1/1 (frame 76/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 30.7ms\n",
      "video 1/1 (frame 77/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.3ms\n",
      "video 1/1 (frame 78/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.5ms\n",
      "video 1/1 (frame 79/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 37.9ms\n",
      "video 1/1 (frame 80/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.0ms\n",
      "video 1/1 (frame 81/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.4ms\n",
      "video 1/1 (frame 82/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.5ms\n",
      "video 1/1 (frame 83/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.3ms\n",
      "video 1/1 (frame 84/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.8ms\n",
      "video 1/1 (frame 85/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.5ms\n",
      "video 1/1 (frame 86/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.2ms\n",
      "video 1/1 (frame 87/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 31.2ms\n",
      "video 1/1 (frame 88/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 32.8ms\n",
      "video 1/1 (frame 89/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 26.0ms\n",
      "video 1/1 (frame 90/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.5ms\n",
      "video 1/1 (frame 91/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 36.7ms\n",
      "video 1/1 (frame 92/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.9ms\n",
      "video 1/1 (frame 93/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.5ms\n",
      "video 1/1 (frame 94/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.8ms\n",
      "video 1/1 (frame 95/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.9ms\n",
      "video 1/1 (frame 96/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.7ms\n",
      "video 1/1 (frame 97/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.7ms\n",
      "video 1/1 (frame 98/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.8ms\n",
      "video 1/1 (frame 99/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.0ms\n",
      "video 1/1 (frame 100/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.6ms\n",
      "video 1/1 (frame 101/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.2ms\n",
      "video 1/1 (frame 102/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 14.0ms\n",
      "video 1/1 (frame 103/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.7ms\n",
      "video 1/1 (frame 104/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.9ms\n",
      "video 1/1 (frame 105/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.4ms\n",
      "video 1/1 (frame 106/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.6ms\n",
      "video 1/1 (frame 107/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 21.8ms\n",
      "video 1/1 (frame 108/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.6ms\n",
      "video 1/1 (frame 109/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 15.0ms\n",
      "video 1/1 (frame 110/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.5ms\n",
      "video 1/1 (frame 111/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.6ms\n",
      "video 1/1 (frame 112/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.6ms\n",
      "video 1/1 (frame 113/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 14.3ms\n",
      "video 1/1 (frame 114/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.5ms\n",
      "video 1/1 (frame 115/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.6ms\n",
      "video 1/1 (frame 116/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.6ms\n",
      "video 1/1 (frame 117/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.5ms\n",
      "video 1/1 (frame 118/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.7ms\n",
      "video 1/1 (frame 119/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.7ms\n",
      "video 1/1 (frame 120/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.8ms\n",
      "video 1/1 (frame 121/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.8ms\n",
      "video 1/1 (frame 122/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.9ms\n",
      "video 1/1 (frame 123/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.7ms\n",
      "video 1/1 (frame 124/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 14.5ms\n",
      "video 1/1 (frame 125/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.5ms\n",
      "video 1/1 (frame 126/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.2ms\n",
      "video 1/1 (frame 127/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.1ms\n",
      "video 1/1 (frame 128/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.2ms\n",
      "video 1/1 (frame 129/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.2ms\n",
      "video 1/1 (frame 130/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.1ms\n",
      "video 1/1 (frame 131/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.0ms\n",
      "video 1/1 (frame 132/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.0ms\n",
      "video 1/1 (frame 133/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 33.7ms\n",
      "video 1/1 (frame 134/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.2ms\n",
      "video 1/1 (frame 135/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 25.9ms\n",
      "video 1/1 (frame 136/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.0ms\n",
      "video 1/1 (frame 137/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 15.6ms\n",
      "video 1/1 (frame 138/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 14.1ms\n",
      "video 1/1 (frame 139/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.1ms\n",
      "video 1/1 (frame 140/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.3ms\n",
      "video 1/1 (frame 141/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.1ms\n",
      "video 1/1 (frame 142/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.8ms\n",
      "video 1/1 (frame 143/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.2ms\n",
      "video 1/1 (frame 144/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 28.0ms\n",
      "video 1/1 (frame 145/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.4ms\n",
      "video 1/1 (frame 146/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.7ms\n",
      "video 1/1 (frame 147/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 17.8ms\n",
      "video 1/1 (frame 148/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 24.6ms\n",
      "video 1/1 (frame 149/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.3ms\n",
      "video 1/1 (frame 150/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.1ms\n",
      "video 1/1 (frame 151/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.9ms\n",
      "video 1/1 (frame 152/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 13.1ms\n",
      "video 1/1 (frame 153/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.8ms\n",
      "video 1/1 (frame 154/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.1ms\n",
      "video 1/1 (frame 155/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.5ms\n",
      "video 1/1 (frame 156/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.3ms\n",
      "video 1/1 (frame 157/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 158/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 159/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 160/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 161/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 23.2ms\n",
      "video 1/1 (frame 162/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 37.1ms\n",
      "video 1/1 (frame 163/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 164/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.5ms\n",
      "video 1/1 (frame 165/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.6ms\n",
      "video 1/1 (frame 166/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 167/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 168/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.0ms\n",
      "video 1/1 (frame 169/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 12.1ms\n",
      "video 1/1 (frame 170/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 robot, 33.4ms\n",
      "video 1/1 (frame 171/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 172/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 173/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 174/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 175/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 176/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 177/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 178/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 179/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 180/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 24.0ms\n",
      "video 1/1 (frame 181/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 182/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 183/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 13.3ms\n",
      "video 1/1 (frame 184/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 185/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 186/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 24.5ms\n",
      "video 1/1 (frame 187/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 11.9ms\n",
      "video 1/1 (frame 188/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 189/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.5ms\n",
      "video 1/1 (frame 190/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 191/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 18.9ms\n",
      "video 1/1 (frame 192/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 193/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 194/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 11.8ms\n",
      "video 1/1 (frame 195/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 196/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 197/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 198/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 199/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 200/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 201/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 202/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 203/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 204/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 205/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 206/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.0ms\n",
      "video 1/1 (frame 207/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 13.4ms\n",
      "video 1/1 (frame 208/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 14.4ms\n",
      "video 1/1 (frame 209/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 31.1ms\n",
      "video 1/1 (frame 210/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.4ms\n",
      "video 1/1 (frame 211/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 16.2ms\n",
      "video 1/1 (frame 212/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 43.8ms\n",
      "video 1/1 (frame 213/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 35.2ms\n",
      "video 1/1 (frame 214/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 11.9ms\n",
      "video 1/1 (frame 215/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.8ms\n",
      "video 1/1 (frame 216/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 217/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 218/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 11.9ms\n",
      "video 1/1 (frame 219/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 35.0ms\n",
      "video 1/1 (frame 220/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 32.0ms\n",
      "video 1/1 (frame 221/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 32.5ms\n",
      "video 1/1 (frame 222/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 223/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 224/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 225/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.6ms\n",
      "video 1/1 (frame 226/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.6ms\n",
      "video 1/1 (frame 227/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 20.2ms\n",
      "video 1/1 (frame 228/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.9ms\n",
      "video 1/1 (frame 229/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 230/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 231/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 13.6ms\n",
      "video 1/1 (frame 232/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 233/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 234/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 235/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 236/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 13.7ms\n",
      "video 1/1 (frame 237/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 26.7ms\n",
      "video 1/1 (frame 238/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 34.5ms\n",
      "video 1/1 (frame 239/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 240/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 241/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 242/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 243/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 244/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 245/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 246/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 247/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 14.0ms\n",
      "video 1/1 (frame 248/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 14.4ms\n",
      "video 1/1 (frame 249/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 14.1ms\n",
      "video 1/1 (frame 250/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 14.0ms\n",
      "video 1/1 (frame 251/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 14.1ms\n",
      "video 1/1 (frame 252/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 14.0ms\n",
      "video 1/1 (frame 253/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 14.2ms\n",
      "video 1/1 (frame 254/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 14.1ms\n",
      "video 1/1 (frame 255/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 14.0ms\n",
      "video 1/1 (frame 256/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 257/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 24.1ms\n",
      "video 1/1 (frame 258/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.9ms\n",
      "video 1/1 (frame 259/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 260/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.9ms\n",
      "video 1/1 (frame 261/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 262/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.9ms\n",
      "video 1/1 (frame 263/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 13.8ms\n",
      "video 1/1 (frame 264/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 13.7ms\n",
      "video 1/1 (frame 265/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 266/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 14.3ms\n",
      "video 1/1 (frame 267/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 268/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 269/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.6ms\n",
      "video 1/1 (frame 270/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 271/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 272/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 273/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 274/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 275/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 276/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 277/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 278/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.9ms\n",
      "video 1/1 (frame 279/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 38.0ms\n",
      "video 1/1 (frame 280/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 34.9ms\n",
      "video 1/1 (frame 281/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 34.7ms\n",
      "video 1/1 (frame 282/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.1ms\n",
      "video 1/1 (frame 283/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 284/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 285/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 4 humans, 1 robot, 12.2ms\n",
      "video 1/1 (frame 286/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 3 humans, 1 robot, 12.6ms\n",
      "video 1/1 (frame 287/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.9ms\n",
      "video 1/1 (frame 288/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 3 humans, 1 robot, 13.8ms\n",
      "video 1/1 (frame 289/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 290/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 13.4ms\n",
      "video 1/1 (frame 291/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.0ms\n",
      "video 1/1 (frame 292/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.1ms\n",
      "video 1/1 (frame 293/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.2ms\n",
      "video 1/1 (frame 294/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 25.6ms\n",
      "video 1/1 (frame 295/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.1ms\n",
      "video 1/1 (frame 296/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.1ms\n",
      "video 1/1 (frame 297/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.2ms\n",
      "video 1/1 (frame 298/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 299/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 300/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 301/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 302/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 303/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 304/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 305/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 306/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 307/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 308/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 309/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 310/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 311/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 27.8ms\n",
      "video 1/1 (frame 312/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 313/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 314/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 315/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 316/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 317/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 318/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 319/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 320/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 321/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 322/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 323/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 324/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 325/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 326/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 34.4ms\n",
      "video 1/1 (frame 327/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 328/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 329/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 330/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 331/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 332/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 333/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 334/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 335/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 336/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 337/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 338/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 339/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 340/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 341/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 342/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 343/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 344/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 345/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.3ms\n",
      "video 1/1 (frame 346/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.9ms\n",
      "video 1/1 (frame 347/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 20.4ms\n",
      "video 1/1 (frame 348/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 349/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 350/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 351/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 352/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 353/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 354/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 355/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 356/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 357/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 358/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 359/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 32.3ms\n",
      "video 1/1 (frame 360/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 29.4ms\n",
      "video 1/1 (frame 361/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 33.0ms\n",
      "video 1/1 (frame 362/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 30.5ms\n",
      "video 1/1 (frame 363/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 364/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 365/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.5ms\n",
      "video 1/1 (frame 366/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 367/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.0ms\n",
      "video 1/1 (frame 368/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.4ms\n",
      "video 1/1 (frame 369/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 370/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.1ms\n",
      "video 1/1 (frame 371/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 372/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.9ms\n",
      "video 1/1 (frame 373/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 374/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 375/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.2ms\n",
      "video 1/1 (frame 376/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 377/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 36.8ms\n",
      "video 1/1 (frame 378/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 24.2ms\n",
      "video 1/1 (frame 379/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.5ms\n",
      "video 1/1 (frame 380/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 381/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.5ms\n",
      "video 1/1 (frame 382/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.4ms\n",
      "video 1/1 (frame 383/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 39.3ms\n",
      "video 1/1 (frame 384/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.4ms\n",
      "video 1/1 (frame 385/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.5ms\n",
      "video 1/1 (frame 386/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.6ms\n",
      "video 1/1 (frame 387/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.5ms\n",
      "video 1/1 (frame 388/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 389/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 390/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 391/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 392/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.5ms\n",
      "video 1/1 (frame 393/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.6ms\n",
      "video 1/1 (frame 394/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 32.2ms\n",
      "video 1/1 (frame 395/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 28.1ms\n",
      "video 1/1 (frame 396/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 29.5ms\n",
      "video 1/1 (frame 397/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 398/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 399/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 400/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 30.8ms\n",
      "video 1/1 (frame 401/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 402/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 403/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 404/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 405/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 406/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 407/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.5ms\n",
      "video 1/1 (frame 408/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.5ms\n",
      "video 1/1 (frame 409/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.9ms\n",
      "video 1/1 (frame 410/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 411/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.6ms\n",
      "video 1/1 (frame 412/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 413/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.6ms\n",
      "video 1/1 (frame 414/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 415/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 416/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 417/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 418/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.5ms\n",
      "video 1/1 (frame 419/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 420/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 421/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 422/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 423/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 424/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 27.2ms\n",
      "video 1/1 (frame 425/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 426/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 427/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 428/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.4ms\n",
      "video 1/1 (frame 429/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 430/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 23.3ms\n",
      "video 1/1 (frame 431/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 432/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 433/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 434/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 435/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 436/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 437/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 438/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 439/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 440/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 441/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 442/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 443/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 444/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 445/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 446/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 447/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 19.3ms\n",
      "video 1/1 (frame 448/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 449/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 450/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 451/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 452/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 453/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 454/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 455/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 456/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 457/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.4ms\n",
      "video 1/1 (frame 458/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 459/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.4ms\n",
      "video 1/1 (frame 460/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 461/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 462/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.9ms\n",
      "video 1/1 (frame 463/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.9ms\n",
      "video 1/1 (frame 464/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 465/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 466/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 467/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 468/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 469/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.9ms\n",
      "video 1/1 (frame 470/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 471/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.9ms\n",
      "video 1/1 (frame 472/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 473/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 474/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 475/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.9ms\n",
      "video 1/1 (frame 476/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 477/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 478/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.9ms\n",
      "video 1/1 (frame 479/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 480/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 481/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 33.0ms\n",
      "video 1/1 (frame 482/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 483/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 484/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 485/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 486/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 487/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 20.6ms\n",
      "video 1/1 (frame 488/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 489/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 490/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 491/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 492/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 493/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 494/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 31.3ms\n",
      "video 1/1 (frame 495/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 496/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 497/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 498/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 499/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 500/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 501/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.8ms\n",
      "video 1/1 (frame 502/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.8ms\n",
      "video 1/1 (frame 503/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.8ms\n",
      "video 1/1 (frame 504/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 505/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 506/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.2ms\n",
      "video 1/1 (frame 507/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 508/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 509/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 510/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.8ms\n",
      "video 1/1 (frame 511/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.7ms\n",
      "video 1/1 (frame 512/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 513/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 514/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 18.4ms\n",
      "video 1/1 (frame 515/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 19.4ms\n",
      "video 1/1 (frame 516/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 18.6ms\n",
      "video 1/1 (frame 517/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 20.8ms\n",
      "video 1/1 (frame 518/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 19.7ms\n",
      "video 1/1 (frame 519/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 18.6ms\n",
      "video 1/1 (frame 520/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 19.2ms\n",
      "video 1/1 (frame 521/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 522/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 523/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 524/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 525/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 526/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 527/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 528/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 529/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 530/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 531/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 532/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 533/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 534/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 34.1ms\n",
      "video 1/1 (frame 535/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 536/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 537/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 538/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.8ms\n",
      "video 1/1 (frame 539/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 540/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 541/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 21.0ms\n",
      "video 1/1 (frame 542/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 543/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 544/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 545/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 546/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 547/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 548/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 549/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 550/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 551/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 552/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 553/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 554/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 25.8ms\n",
      "video 1/1 (frame 555/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 32.2ms\n",
      "video 1/1 (frame 556/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.3ms\n",
      "video 1/1 (frame 557/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 558/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.3ms\n",
      "video 1/1 (frame 559/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 560/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.3ms\n",
      "video 1/1 (frame 561/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.5ms\n",
      "video 1/1 (frame 562/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.2ms\n",
      "video 1/1 (frame 563/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.6ms\n",
      "video 1/1 (frame 564/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 565/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 566/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 19.1ms\n",
      "video 1/1 (frame 567/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.7ms\n",
      "video 1/1 (frame 568/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 569/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 570/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 571/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 572/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.6ms\n",
      "video 1/1 (frame 573/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 574/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 23.9ms\n",
      "video 1/1 (frame 575/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 576/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 577/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 578/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 579/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 18.6ms\n",
      "video 1/1 (frame 580/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 581/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 44.6ms\n",
      "video 1/1 (frame 582/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 583/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 584/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 585/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 586/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 587/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.1ms\n",
      "video 1/1 (frame 588/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 589/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 590/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 591/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 592/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 593/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 594/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 595/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 596/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 597/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 598/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 599/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 600/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 601/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 602/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 603/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 604/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 605/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 606/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 607/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 608/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 609/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 30.3ms\n",
      "video 1/1 (frame 610/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 32.7ms\n",
      "video 1/1 (frame 611/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 612/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 613/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 614/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 615/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 616/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 617/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 618/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 619/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 620/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 32.2ms\n",
      "video 1/1 (frame 621/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 622/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 623/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 624/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 625/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 626/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 627/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 628/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 629/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 630/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 631/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 632/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 633/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 634/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.3ms\n",
      "video 1/1 (frame 635/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 44.6ms\n",
      "video 1/1 (frame 636/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.2ms\n",
      "video 1/1 (frame 637/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 17.7ms\n",
      "video 1/1 (frame 638/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 47.3ms\n",
      "video 1/1 (frame 639/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.5ms\n",
      "video 1/1 (frame 640/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.5ms\n",
      "video 1/1 (frame 641/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 20.4ms\n",
      "video 1/1 (frame 642/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.5ms\n",
      "video 1/1 (frame 643/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.6ms\n",
      "video 1/1 (frame 644/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.8ms\n",
      "video 1/1 (frame 645/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.5ms\n",
      "video 1/1 (frame 646/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 31.2ms\n",
      "video 1/1 (frame 647/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.8ms\n",
      "video 1/1 (frame 648/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.4ms\n",
      "video 1/1 (frame 649/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.1ms\n",
      "video 1/1 (frame 650/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.0ms\n",
      "video 1/1 (frame 651/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.2ms\n",
      "video 1/1 (frame 652/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 653/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 654/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.8ms\n",
      "video 1/1 (frame 655/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 19.9ms\n",
      "video 1/1 (frame 656/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.8ms\n",
      "video 1/1 (frame 657/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 658/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 30.0ms\n",
      "video 1/1 (frame 659/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 31.0ms\n",
      "video 1/1 (frame 660/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 661/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 662/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 33.9ms\n",
      "video 1/1 (frame 663/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 664/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 17.0ms\n",
      "video 1/1 (frame 665/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 666/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 667/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.8ms\n",
      "video 1/1 (frame 668/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 669/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 670/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 671/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.8ms\n",
      "video 1/1 (frame 672/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 673/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 674/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 675/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.8ms\n",
      "video 1/1 (frame 676/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 677/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 678/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 679/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 680/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 681/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 682/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 683/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 684/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 685/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 686/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 687/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 688/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 689/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 24.4ms\n",
      "video 1/1 (frame 690/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.5ms\n",
      "video 1/1 (frame 691/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 692/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 693/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 694/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 695/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 23.1ms\n",
      "video 1/1 (frame 696/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 697/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 698/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 699/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 700/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 701/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.8ms\n",
      "video 1/1 (frame 702/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 703/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 704/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 705/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 706/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 707/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 708/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 709/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 710/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 711/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 712/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 713/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 714/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 32.9ms\n",
      "video 1/1 (frame 715/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 716/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 717/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 718/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 29.9ms\n",
      "video 1/1 (frame 719/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.8ms\n",
      "video 1/1 (frame 720/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 721/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 722/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 723/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 17.0ms\n",
      "video 1/1 (frame 724/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 26.8ms\n",
      "video 1/1 (frame 725/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 24.5ms\n",
      "video 1/1 (frame 726/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 727/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 728/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 36.1ms\n",
      "video 1/1 (frame 729/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.3ms\n",
      "video 1/1 (frame 730/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.2ms\n",
      "video 1/1 (frame 731/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 732/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.6ms\n",
      "video 1/1 (frame 733/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.0ms\n",
      "video 1/1 (frame 734/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.8ms\n",
      "video 1/1 (frame 735/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.7ms\n",
      "video 1/1 (frame 736/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.7ms\n",
      "video 1/1 (frame 737/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 738/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.5ms\n",
      "video 1/1 (frame 739/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 740/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.5ms\n",
      "video 1/1 (frame 741/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 742/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 743/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 17.3ms\n",
      "video 1/1 (frame 744/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.3ms\n",
      "video 1/1 (frame 745/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 746/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 19.6ms\n",
      "video 1/1 (frame 747/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 24.9ms\n",
      "video 1/1 (frame 748/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 33.5ms\n",
      "video 1/1 (frame 749/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 36.7ms\n",
      "video 1/1 (frame 750/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 22.1ms\n",
      "video 1/1 (frame 751/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.9ms\n",
      "video 1/1 (frame 752/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 31.5ms\n",
      "video 1/1 (frame 753/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 29.1ms\n",
      "video 1/1 (frame 754/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.0ms\n",
      "video 1/1 (frame 755/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.0ms\n",
      "video 1/1 (frame 756/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.3ms\n",
      "video 1/1 (frame 757/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.2ms\n",
      "video 1/1 (frame 758/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 17.3ms\n",
      "video 1/1 (frame 759/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.0ms\n",
      "video 1/1 (frame 760/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 17.3ms\n",
      "video 1/1 (frame 761/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.2ms\n",
      "video 1/1 (frame 762/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 763/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.2ms\n",
      "video 1/1 (frame 764/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 765/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 19.3ms\n",
      "video 1/1 (frame 766/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.4ms\n",
      "video 1/1 (frame 767/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.3ms\n",
      "video 1/1 (frame 768/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.2ms\n",
      "video 1/1 (frame 769/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 20.0ms\n",
      "video 1/1 (frame 770/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.7ms\n",
      "video 1/1 (frame 771/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 35.7ms\n",
      "video 1/1 (frame 772/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 24.5ms\n",
      "video 1/1 (frame 773/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 18.0ms\n",
      "video 1/1 (frame 774/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.2ms\n",
      "video 1/1 (frame 775/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 776/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 777/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 778/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 23.1ms\n",
      "video 1/1 (frame 779/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 21.6ms\n",
      "video 1/1 (frame 780/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 781/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 782/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 783/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 784/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 785/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 786/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 32.3ms\n",
      "video 1/1 (frame 787/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 788/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 18.3ms\n",
      "video 1/1 (frame 789/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 790/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 28.0ms\n",
      "video 1/1 (frame 791/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.7ms\n",
      "video 1/1 (frame 792/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.1ms\n",
      "video 1/1 (frame 793/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 794/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 795/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 796/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 19.6ms\n",
      "video 1/1 (frame 797/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 798/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 17.1ms\n",
      "video 1/1 (frame 799/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.9ms\n",
      "video 1/1 (frame 800/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 29.1ms\n",
      "video 1/1 (frame 801/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.5ms\n",
      "video 1/1 (frame 802/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 16.6ms\n",
      "video 1/1 (frame 803/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.8ms\n",
      "video 1/1 (frame 804/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 805/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 806/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 17.8ms\n",
      "video 1/1 (frame 807/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 20.6ms\n",
      "video 1/1 (frame 808/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 18.2ms\n",
      "video 1/1 (frame 809/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 810/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 811/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 812/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 813/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 814/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 815/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 816/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.7ms\n",
      "video 1/1 (frame 817/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 818/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 26.9ms\n",
      "video 1/1 (frame 819/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 18.4ms\n",
      "video 1/1 (frame 820/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.8ms\n",
      "video 1/1 (frame 821/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 822/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 823/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 824/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 825/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 826/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 827/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 828/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 829/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 22.0ms\n",
      "video 1/1 (frame 830/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 831/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 832/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 833/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 834/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 36.3ms\n",
      "video 1/1 (frame 835/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 836/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 837/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 838/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 839/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 840/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 841/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 842/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 843/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 844/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 845/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.3ms\n",
      "video 1/1 (frame 846/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.4ms\n",
      "video 1/1 (frame 847/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 848/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 849/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 850/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 851/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 852/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 853/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 854/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 855/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 856/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.3ms\n",
      "video 1/1 (frame 857/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 858/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.0ms\n",
      "video 1/1 (frame 859/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.6ms\n",
      "video 1/1 (frame 860/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 861/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 862/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 863/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.8ms\n",
      "video 1/1 (frame 864/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 865/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 866/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 867/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 868/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.2ms\n",
      "video 1/1 (frame 869/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 870/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 871/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 872/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 873/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 874/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.3ms\n",
      "video 1/1 (frame 875/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 876/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.6ms\n",
      "video 1/1 (frame 877/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 878/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 879/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 880/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 34.6ms\n",
      "video 1/1 (frame 881/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 882/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 883/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 36.5ms\n",
      "video 1/1 (frame 884/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 15.4ms\n",
      "video 1/1 (frame 885/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 886/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 887/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 888/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 889/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 890/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.6ms\n",
      "video 1/1 (frame 891/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 892/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 893/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 894/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 32.1ms\n",
      "video 1/1 (frame 895/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 896/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 21.5ms\n",
      "video 1/1 (frame 897/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 19.9ms\n",
      "video 1/1 (frame 898/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 17.5ms\n",
      "video 1/1 (frame 899/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.7ms\n",
      "video 1/1 (frame 900/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.3ms\n",
      "video 1/1 (frame 901/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.3ms\n",
      "video 1/1 (frame 902/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.4ms\n",
      "video 1/1 (frame 903/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 27.2ms\n",
      "video 1/1 (frame 904/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.4ms\n",
      "video 1/1 (frame 905/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 906/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.4ms\n",
      "video 1/1 (frame 907/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.3ms\n",
      "video 1/1 (frame 908/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 909/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.3ms\n",
      "video 1/1 (frame 910/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.3ms\n",
      "video 1/1 (frame 911/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.3ms\n",
      "video 1/1 (frame 912/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 913/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.3ms\n",
      "video 1/1 (frame 914/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.6ms\n",
      "video 1/1 (frame 915/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 916/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 917/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 918/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 919/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 920/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.6ms\n",
      "video 1/1 (frame 921/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 922/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 923/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 924/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 925/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 926/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 927/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 41.2ms\n",
      "video 1/1 (frame 928/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 929/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 930/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 931/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 932/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 933/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.9ms\n",
      "video 1/1 (frame 934/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 935/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 936/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 937/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 938/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 32.4ms\n",
      "video 1/1 (frame 939/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.8ms\n",
      "video 1/1 (frame 940/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 941/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 942/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 943/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 944/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.4ms\n",
      "video 1/1 (frame 945/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.4ms\n",
      "video 1/1 (frame 946/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.6ms\n",
      "video 1/1 (frame 947/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 948/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 949/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.8ms\n",
      "video 1/1 (frame 950/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 13.0ms\n",
      "video 1/1 (frame 951/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 20.3ms\n",
      "video 1/1 (frame 952/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.7ms\n",
      "video 1/1 (frame 953/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 12.8ms\n",
      "video 1/1 (frame 954/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.5ms\n",
      "video 1/1 (frame 955/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.9ms\n",
      "video 1/1 (frame 956/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 13.0ms\n",
      "video 1/1 (frame 957/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 26.4ms\n",
      "video 1/1 (frame 958/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 12.7ms\n",
      "video 1/1 (frame 959/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 13.0ms\n",
      "video 1/1 (frame 960/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 13.9ms\n",
      "video 1/1 (frame 961/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 2 humans, 1 robot, 13.9ms\n",
      "video 1/1 (frame 962/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.1ms\n",
      "video 1/1 (frame 963/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.5ms\n",
      "video 1/1 (frame 964/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 965/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 966/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.0ms\n",
      "video 1/1 (frame 967/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.2ms\n",
      "video 1/1 (frame 968/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 969/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "video 1/1 (frame 970/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.3ms\n",
      "video 1/1 (frame 971/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 14.0ms\n",
      "video 1/1 (frame 972/972) /mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4: 384x640 1 human, 1 robot, 13.1ms\n",
      "Speed: 2.9ms preprocess, 15.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/detect/video_results\u001b[0m\n",
      "972 labels saved to runs/detect/video_results/labels\n",
      "Output video saved at: runs/detect/video_results/video1.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Step 1: Load the trained model\n",
    "model_path = \"runs/detect/custom_yolov8m/weights/best.pt\"  # Path to the trained model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Step 2: Perform inference on a video\n",
    "input_video = \"/mnt/c/Users/adnan/Desktop/urfikhan/video1.mp4\"  # Path to the input video\n",
    "output_video = \"/mnt/c/Users/adnan/Desktop/urfikhan/output_video1.mp4\"  # Path to save the output video\n",
    "\n",
    "# Run object detection on the video\n",
    "results = model.predict(source=input_video, save=True, save_txt=True, project=\"runs/detect\", name=\"video_results\")\n",
    "\n",
    "# Step 3: Save the output video with detected objects\n",
    "# The output video is automatically saved by YOLOv8 in the `runs/detect/video_results` folder\n",
    "print(f\"Output video saved at: runs/detect/video_results/{input_video.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed0f36b-3d45-460a-9efa-36f153eb2ce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs/detect/custom_yolov8m9/weights/best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Step 1: Load the trained model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruns/detect/custom_yolov8m9/weights/best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Path to the trained model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Step 2: Perform inference on a video\u001b[39;00m\n\u001b[1;32m      8\u001b[0m input_video \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Path to the input video\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/models/yolo/model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/engine/model.py:148\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/engine/model.py:290\u001b[0m, in \u001b[0;36mModel._load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    287\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/nn/tasks.py:1039\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m    Load a single model weights.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;124;03m        (tuple): Tuple containing the model and checkpoint.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/nn/tasks.py:944\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight, safe_only)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(f, pickle_module\u001b[38;5;241m=\u001b[39msafe_pickle)\n\u001b[1;32m    943\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 944\u001b[0m             ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/ultralytics/utils/patches.py:86\u001b[0m, in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     84\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_torch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/serialization.py:1425\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1423\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1425\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1427\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1428\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1429\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1430\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/serialization.py:751\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 751\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/opencv_gpu/lib/python3.9/site-packages/torch/serialization.py:732\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/detect/custom_yolov8m9/weights/best.pt'"
     ]
    }
   ],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Step 1: Load the trained model\n",
    "model_path = \"runs/detect/custom_yolov8m9/weights/best.pt\"  # Path to the trained model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Step 2: Perform inference on a video\n",
    "input_video = \"/mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4\"  # Path to the input video\n",
    "output_video = \"/mnt/c/Users/adnan/Desktop/urfikhan/output_video2.mp4\"  # Path to save the output video\n",
    "\n",
    "# Run object detection on the video\n",
    "results = model.predict(source=input_video, save=True, save_txt=True, project=\"runs/detect\", name=\"video_results\")\n",
    "\n",
    "# Step 3: Save the output video with detected objects\n",
    "# The output video is automatically saved by YOLOv8 in the `runs/detect/video_results` folder\n",
    "print(f\"Output video saved at: runs/detect/video_results/{input_video.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e68c590-c1d6-4112-a292-2e1c70ba624a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(python:4641): GStreamer-CRITICAL **: 21:56:56.125: gst_element_make_from_uri: assertion 'gst_uri_is_valid (uri)' failed\n",
      "[ WARN:0@1.124] global cap_gstreamer.cpp:2618 open OpenCV | GStreamer warning: cannot link elements\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 human, 1 robot, 73.8ms\n",
      "Speed: 5.8ms preprocess, 73.8ms inference, 143.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 15.2ms\n",
      "Speed: 1.3ms preprocess, 15.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 15.2ms\n",
      "Speed: 1.4ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 15.1ms\n",
      "Speed: 1.4ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 17.5ms\n",
      "Speed: 1.4ms preprocess, 17.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 15.1ms\n",
      "Speed: 1.3ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 15.2ms\n",
      "Speed: 1.1ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 15.1ms\n",
      "Speed: 1.2ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 15.0ms\n",
      "Speed: 1.2ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 15.1ms\n",
      "Speed: 1.3ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 14.3ms\n",
      "Speed: 1.4ms preprocess, 14.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.4ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.6ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.5ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.7ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.6ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.6ms\n",
      "Speed: 1.8ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.6ms\n",
      "Speed: 1.3ms preprocess, 12.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 15.1ms\n",
      "Speed: 2.0ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.6ms\n",
      "Speed: 1.8ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.5ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.6ms\n",
      "Speed: 1.7ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.7ms\n",
      "Speed: 1.7ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.6ms\n",
      "Speed: 1.5ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.7ms\n",
      "Speed: 1.2ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.6ms\n",
      "Speed: 1.4ms preprocess, 12.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 16.2ms\n",
      "Speed: 2.2ms preprocess, 16.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.5ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.8ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.8ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.5ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.5ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.5ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.6ms\n",
      "Speed: 1.2ms preprocess, 12.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 15.6ms\n",
      "Speed: 1.6ms preprocess, 15.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.6ms\n",
      "Speed: 1.2ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 19.6ms\n",
      "Speed: 2.1ms preprocess, 19.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.6ms\n",
      "Speed: 1.2ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.6ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.5ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.8ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 18.6ms\n",
      "Speed: 2.6ms preprocess, 18.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.5ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.4ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.8ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.6ms\n",
      "Speed: 1.1ms preprocess, 12.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.8ms\n",
      "Speed: 1.5ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.5ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.4ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 13.1ms\n",
      "Speed: 2.7ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.6ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.0ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.7ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.3ms preprocess, 12.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.7ms\n",
      "Speed: 1.2ms preprocess, 12.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.3ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.6ms\n",
      "Speed: 1.2ms preprocess, 12.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.3ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 3.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.0ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.0ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.6ms\n",
      "Speed: 1.2ms preprocess, 12.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.8ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.6ms\n",
      "Speed: 1.3ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.2ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.0ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.1ms preprocess, 12.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.5ms\n",
      "Speed: 1.2ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 13.2ms\n",
      "Speed: 1.1ms preprocess, 13.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.7ms\n",
      "Speed: 1.1ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.2ms preprocess, 12.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.1ms preprocess, 12.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 19.6ms\n",
      "Speed: 1.2ms preprocess, 19.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.1ms preprocess, 12.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 human, 1 robot, 12.4ms\n",
      "Speed: 1.0ms preprocess, 12.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Step 1: Load your trained YOLOv8 model\n",
    "model = YOLO(\"runs/detect/custom_yolov8m/weights/best.pt\")  # Replace with the path to your trained model\n",
    "\n",
    "# Step 2: Check if GPU is available and set the device\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Step 3: Define the input video path\n",
    "input_video_path = \"/mnt/c/Users/adnan/Desktop/urfikhan/video2.mp4\"  # Replace with the path to your input video\n",
    "\n",
    "# Step 4: Define the output video path (in the same folder as the input video)\n",
    "output_video_folder = os.path.dirname(input_video_path)  # Get the folder of the input video\n",
    "output_video_name = os.path.splitext(os.path.basename(input_video_path))[0] + \"video_detected2.mp4\"\n",
    "output_video_path = os.path.join(output_video_folder, output_video_name)\n",
    "\n",
    "# Step 5: Open the input video\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Get video properties\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Step 6: Create a VideoWriter object to save the output video in MP4 format\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4 format\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Step 7: Perform object detection on each frame and save the output\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform object detection on the frame using the specified device (GPU or CPU)\n",
    "    results = model.predict(frame, conf=0.5, device=device)  # Use GPU if available\n",
    "\n",
    "    # Visualize the results on the frame\n",
    "    annotated_frame = results[0].plot()  # Get the annotated frame\n",
    "\n",
    "    # Write the annotated frame to the output video\n",
    "    out.write(annotated_frame)\n",
    "\n",
    "# Step 8: Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Step 9: Print the path to the saved output video\n",
    "print(f\"Input video: {input_video_path}\")\n",
    "print(f\"Output video saved at: {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea3ad9-363a-4ff2-9145-3ba257c63669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
